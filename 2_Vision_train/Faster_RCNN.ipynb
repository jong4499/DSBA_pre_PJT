{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j9zFyb1TKxD",
        "outputId": "d7813be6-0d19-4224-c915-40501aeba6e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch:1.9.1+cu111\\(NVIDIA GeForce RTX 3060)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\pre_pjt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"torch:{torch.__version__}\\({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting beautifulsoup4\n",
            "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
            "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4\n",
            "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nm7_2VEHTm-M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import random\n",
        "import cv2\n",
        "import time\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import torch\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZQFgx6ZTfU8",
        "outputId": "8a053184-fe61-4bc1-d879-cb139bcc540f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4847\n",
            "4847\n"
          ]
        }
      ],
      "source": [
        "img_lst = glob.glob('C:/Users/admin/Desktop/data_V4/images/*.jpg')\n",
        "annot_lst = glob.glob('C:/Users/admin/Desktop/data_V4/annotations/*.xml')\n",
        "print(len(img_lst))\n",
        "print(len(annot_lst))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.remove('C:/Users/admin/Desktop/data_V4/images/desktop.ini')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "44fjv8R1VDhU"
      },
      "outputs": [],
      "source": [
        "os.mkdir ('C:/Users/admin/Desktop/data_V4/test_images')\n",
        "os.mkdir ('C:/Users/admin/Desktop/data_V4/test_annotations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWw7bjKZlIt5",
        "outputId": "a23ca836-7842-4277-baa8-399c1d41bb18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170\n",
            "[451, 119, 7, 92, 596, 35, 85, 100, 363, 242]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.seed(1234)\n",
        "idx = random.sample(range(641), 170)\n",
        "print(len(idx))\n",
        "print(idx[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pntyGH1llKjp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "for img in np.array(sorted(os.listdir('C:/Users/admin/Desktop/data_V4/images')))[idx]:\n",
        "    shutil.move('C:/Users/admin/Desktop/data_V4/images/'+img, 'C:/Users/admin/Desktop/data_V4/test_images/'+img)\n",
        "\n",
        "for annot in np.array(sorted(os.listdir('C:/Users/admin/Desktop/data_V4/annotations')))[idx]:\n",
        "    shutil.move('C:/Users/admin/Desktop/data_V4/annotations/'+annot, 'C:/Users/admin/Desktop/data_V4/test_annotations/'+annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS4UNXqIlL_h",
        "outputId": "f1a06dc0-338d-454b-fc58-927fcd7e4292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4677\n",
            "4677\n",
            "170\n",
            "170\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir('C:/Users/admin/Desktop/data_V4/annotations')))\n",
        "print(len(os.listdir('C:/Users/admin/Desktop/data_V4/images')))\n",
        "print(len(os.listdir('C:/Users/admin/Desktop/data_V4/test_annotations')))\n",
        "print(len(os.listdir('C:/Users/admin/Desktop/data_V4/test_images')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "k8-XIZTPXo2E"
      },
      "outputs": [],
      "source": [
        "def generate_box(obj):\n",
        "\n",
        "    xmin = float(obj.find('xmin').text)\n",
        "    ymin = float(obj.find('ymin').text)\n",
        "    xmax = float(obj.find('xmax').text)\n",
        "    ymax = float(obj.find('ymax').text)\n",
        "\n",
        "    return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "\n",
        "def generate_label(obj):\n",
        "    return 0\n",
        "\n",
        "\n",
        "def generate_target(file):\n",
        "    with open(file) as f:\n",
        "        data = f.read()\n",
        "        soup = BeautifulSoup(data, \"html.parser\")\n",
        "        objects = soup.find_all(\"object\")\n",
        "\n",
        "        num_objs = len(objects)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for i in objects:\n",
        "            boxes.append(generate_box(i))\n",
        "            labels.append(generate_label(i))\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "\n",
        "        return target\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sL3zGB_yibQZ"
      },
      "outputs": [],
      "source": [
        "class Dataset_transformer(object):\n",
        "    def __init__(self, transforms, path):\n",
        "        self.transforms = transforms\n",
        "        self.path = path\n",
        "        self.imgs = list(sorted(os.listdir(self.path)))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_image = self.imgs[idx]\n",
        "        file_label = self.imgs[idx][:-3] + 'xml'\n",
        "        img_path = os.path.join(self.path, file_image)\n",
        "\n",
        "        if 'test' in self.path:\n",
        "            label_path = os.path.join(\"C:/Users/admin/Desktop/data_V4/test_annotations/\", file_label)\n",
        "        else:\n",
        "            label_path = os.path.join(\"C:/Users/admin/Desktop/data_V4/annotations/\", file_label)\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        target = generate_target(label_path)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nP7U0b0yiiKR"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "IjkCN_VtesRa"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset_transformer(data_transform, 'C:/Users/admin/Desktop/data_V4/images/')\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=4, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Yt0uddD-Z6sZ"
      },
      "outputs": [],
      "source": [
        "test_dataset = Dataset_transformer(data_transform, 'C:/Users/admin/Desktop/data_V4/test_images/')\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tXtumEaUUbDt"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ceqcNDp0Uffk"
      },
      "outputs": [],
      "source": [
        "def get_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRQBbn2pUgEb",
        "outputId": "09aa15c8-823b-4431-9235-df07e245519f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to C:\\Users\\admin/.cache\\torch\\hub\\checkpoints\\fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:10<00:00, 15.3MB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=1, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = get_model(1)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HN32sBUUkMb",
        "outputId": "57907dc1-0b3c-49b5-99e2-7787422400d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4Q1S00e_UhOT"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNZ51v9fUiWz",
        "outputId": "00d82c84-90c2-4256-adb2-437039ee2df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------train start--------------------------\n",
            "epoch : 1, Loss : 45.72172546386719, time : 901.9207012653351\n",
            "epoch : 2, Loss : 32.95088195800781, time : 900.406046628952\n",
            "epoch : 3, Loss : 30.59593963623047, time : 900.5560805797577\n",
            "epoch : 4, Loss : 29.523103713989258, time : 900.2224538326263\n",
            "epoch : 5, Loss : 28.996932983398438, time : 900.5072689056396\n",
            "epoch : 6, Loss : 28.90983772277832, time : 899.8542602062225\n",
            "epoch : 7, Loss : 28.343542098999023, time : 899.6052398681641\n",
            "epoch : 8, Loss : 28.258258819580078, time : 899.7053425312042\n",
            "epoch : 9, Loss : 28.2061710357666, time : 898.938038110733\n",
            "epoch : 10, Loss : 27.57108497619629, time : 899.3049802780151\n",
            "epoch : 11, Loss : 27.082443237304688, time : 899.1226403713226\n",
            "epoch : 12, Loss : 26.527917861938477, time : 899.0871086120605\n",
            "epoch : 13, Loss : 25.90780258178711, time : 898.9044630527496\n",
            "epoch : 14, Loss : 25.511919021606445, time : 898.8212013244629\n",
            "epoch : 15, Loss : 25.298513412475586, time : 899.1721782684326\n",
            "epoch : 16, Loss : 25.162979125976562, time : 899.0209658145905\n",
            "epoch : 17, Loss : 25.04996109008789, time : 899.3017909526825\n",
            "epoch : 18, Loss : 24.919355392456055, time : 899.2125885486603\n",
            "epoch : 19, Loss : 24.839967727661133, time : 899.2169947624207\n",
            "epoch : 20, Loss : 24.860387802124023, time : 899.4396119117737\n",
            "epoch : 21, Loss : 24.67779541015625, time : 899.370662689209\n",
            "epoch : 22, Loss : 24.767580032348633, time : 899.5052943229675\n",
            "epoch : 23, Loss : 25.075531005859375, time : 900.1391401290894\n",
            "epoch : 24, Loss : 25.007165908813477, time : 899.7388799190521\n",
            "epoch : 25, Loss : 25.227603912353516, time : 899.5382115840912\n",
            "epoch : 26, Loss : 25.18901252746582, time : 899.2887687683105\n",
            "epoch : 27, Loss : 25.044824600219727, time : 899.3218474388123\n",
            "epoch : 28, Loss : 25.403705596923828, time : 899.4559798240662\n",
            "epoch : 29, Loss : 25.784927368164062, time : 899.1226027011871\n",
            "epoch : 30, Loss : 25.883230209350586, time : 899.3044047355652\n",
            "epoch : 31, Loss : 25.727876663208008, time : 899.5217640399933\n",
            "epoch : 32, Loss : 25.516429901123047, time : 899.4376122951508\n",
            "epoch : 33, Loss : 26.158899307250977, time : 899.4229071140289\n",
            "epoch : 34, Loss : 26.244274139404297, time : 899.0718824863434\n",
            "epoch : 35, Loss : 26.266721725463867, time : 899.172114610672\n",
            "epoch : 36, Loss : 25.843257904052734, time : 899.0544703006744\n",
            "epoch : 37, Loss : 26.840124130249023, time : 899.607161283493\n",
            "epoch : 38, Loss : 26.6323299407959, time : 899.8731415271759\n",
            "epoch : 39, Loss : 27.0079288482666, time : 899.4733159542084\n",
            "epoch : 40, Loss : 28.520566940307617, time : 899.7727570533752\n",
            "epoch : 41, Loss : 26.364669799804688, time : 900.8395662307739\n",
            "epoch : 42, Loss : 25.9549503326416, time : 900.95600938797\n",
            "epoch : 43, Loss : 26.012413024902344, time : 900.9581298828125\n",
            "epoch : 44, Loss : 26.802583694458008, time : 901.3904592990875\n",
            "epoch : 45, Loss : 26.37586212158203, time : 901.6909580230713\n",
            "epoch : 46, Loss : 26.688812255859375, time : 901.6237614154816\n",
            "epoch : 47, Loss : 26.41767120361328, time : 899.1592288017273\n",
            "epoch : 48, Loss : 26.238027572631836, time : 880.7032868862152\n",
            "epoch : 49, Loss : 26.041889190673828, time : 877.8822512626648\n",
            "epoch : 50, Loss : 26.205957412719727, time : 871.9974048137665\n"
          ]
        }
      ],
      "source": [
        "print('----------------------train start--------------------------')\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    i = 1\n",
        "    epoch_loss = 0\n",
        "    for imgs, annotations in data_loader:\n",
        "        i += 1\n",
        "        imgs = list(img.to(device) for img in imgs)\n",
        "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
        "        loss_dict = model(imgs, annotations)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += losses\n",
        "    print(f'epoch : {epoch+1}, Loss : {epoch_loss}, time : {time.time() - start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),f'C:/Users/admin/Desktop/RCNN_{num_epochs}.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
